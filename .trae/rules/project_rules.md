# 背景：
我有 2台 RTX 3090 显卡。我想要布置一个自己的大模型。跑在Docker上。用的是Qwen2.5-7B模型。主要是个人开发使用。2张显卡并行推理。

# 需求：
1. 端口暴露。
2. 对话存储。
3. 简单的api-gateway 和简单的鉴权。

# 虚拟机的配置和文件地址：
我会把当前文件放到：~/test-llama/

！！！！！ 因为 是个人开发使用，所以鉴权和其他代码方便不需要特别严谨。！！！！！


